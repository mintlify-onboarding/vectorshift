---
title: "Analyst"
---

**Scenario: Say for example I am an analyst at a financial institution and want to produce a bot that helps me answer complex questions logically based on certain files.** 

At a high level, we need:

1. A way for the users to input files and embed them into a Vector database.

2. A way for the user to ask a question and for an LLM to “break down” the broader question into “sub-questions”.

3. A way for a second LLM to receive the relevant information queried using the sub-questions from the Vectorbase to synthesize an answer.

## Step 1 - Open the Pipeline Builder

Click “Build a Pipeline” within the “Overview” tab or click “Build” within the “Pipeline” tab.

![](https://lh4.googleusercontent.com/HH2YJNvx1OoB_bfNbV1ISwpTQdS5V9BosDoDRWMm6DaoGGG75Juxtm743Vux6506Jrqdni3fr6gk2u3sBDkbyFpBhCRA6X_fxpBLrtHXPhfXszR10EhKfoZLVRatn6XqCZ_MT75MhQs6UqmPWRVpryc)

## Step 2 - Embed Files

Allow for end users to feed in files and for them to be embedded in a [VectorDB](/vectorshift/platform/pipelines/vector-db):

1. Utilize an [Input](/vectorshift/platform/pipelines/inputs-outputs#input-nodes) node with the “`type`” adjusted to “`file`” so the user can input a file.

2. Utilize a file loader note to convert the file to a format that a [VectorDB](/vectorshift/platform/pipelines/vector-db) can understand.

3. Connect the file loader to a [VectorDB](/vectorshift/platform/pipelines/vector-db) loader and Reader to load the file into the database and allow for database queries.

![](https://lh3.googleusercontent.com/KfIyHEmLc-rpZnLCjBluT4v2mX2XJSfP8OJUV-HlM7lxKLFa0N9sep5d_SNl851dMcORzrwGvUBL3UV17xMjlNI49vwclqPcdoidaCW8ElFqhICmVp0lyXenWUq9_TwPmZkSO9svX0TFXl2KZw4mU8I)

## Step 3 - Breaking Down The Logic

Create an engine that breaks down the user questions into sub-questions to allow for greater logical analysis.

1. We create another [Input](/vectorshift/platform/pipelines/inputs-outputs#input-nodes) node. This input node accepts “text” and allows the user to submit a question. We connect this node to the “prompt” node of the LLM.

2. We prompt the LLM to break down the question into three additional ones. In the [Text](/vectorshift/platform/pipelines/text) node, we specify the exact output structure of the question. We connect this [Text](/vectorshift/platform/pipelines/text) node to the “system” node of the LLM.

3. We then pass the output of the LLM into a custom data [Transformation](/vectorshift/platform/transformations) that we wrote in Python. This takes a string of questions in the specified output structure and breaks them down individually.

4. We pass these questions as a query into the [VectorDB](/vectorshift/platform/pipelines/vector-db) from above to look for relevant information.

![](https://lh6.googleusercontent.com/SjIOvyQY4LaPYb2jUtX--uj6wFf2LArXzCLyKcZJuFNruZE4XAsODAbyjsiv-k8KKwWAQGNMX02i1wrHebFxFp0rOYPcTtmsBdp1wklf_G0W_mPFiB7ky4CdUG0W3k5UOWTLduJN1MGh6jfBUyIiIDg)

## Step 4 - Use Second LLM

Second LLM to receive the information queried using the sub-questions, synthesize it, and generate an output.

1. Connect the output of the [VectorDB](/vectorshift/platform/pipelines/vector-db) as “Context” in a text node that will be used as a prompt for the second LLM.

2. Connect the [Input](/vectorshift/platform/pipelines/inputs-outputs) with the question the user asked into the prompt.

3. Connect the [Text](/vectorshift/platform/pipelines/text) node as the prompt into the second LLM.

4. Create a [Text](/vectorshift/platform/pipelines/text) node to instruct how the second LLM should behave.

5. Connect an [Output](/vectorshift/platform/pipelines/inputs-outputs) node to the output node of the LLM.

![](https://lh6.googleusercontent.com/NDZ92XGgz5ezvo8yayYUFLwtaLfcZekaNJzbJrLX8jmJYuRgA0YDk9f2gl2gU3mosfuITIBMMwC0AsZ9JQfvavKb9Z2MD4iTK_SazXAuB-ySSkNJQxljT0eu4awtX9R7wG6NXc-F34Nsm4tCsYe661U)

![](https://lh5.googleusercontent.com/mCNxDMcEroe8II0CyMNldrf_JdjeDnQNZw6Gg-u2HWR3dUE0-QHPb5nK7T5sOD01X1CXe4pm9qUWOi4X1svvSKuLI6ScJ-bJ4Ho3cFKw-Qm3zGUHTaZO4M2wWyXVOge_vyl9LZ_2ZES8vJalkDaYbso)

Full pipeline (click to enlarge)